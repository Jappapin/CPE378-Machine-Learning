{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S8scE3fF4346"
   },
   "source": [
    "# Neuron Network - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JHXp_P3e4349"
   },
   "source": [
    "### Part 1: Load  data\n",
    "\n",
    "Import \"bank-data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27599,
     "status": "ok",
     "timestamp": 1614216840852,
     "user": {
      "displayName": "nampetch rodprasert",
      "photoUrl": "",
      "userId": "15290855941941327898"
     },
     "user_tz": -420
    },
    "id": "PCm-oPW_0bQN",
    "outputId": "d460a5d5-b6b8-4f00-de8a-43a272e0228b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 928,
     "status": "ok",
     "timestamp": 1614216909608,
     "user": {
      "displayName": "nampetch rodprasert",
      "photoUrl": "",
      "userId": "15290855941941327898"
     },
     "user_tz": -420
    },
    "id": "ofsD_P06434-"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "bankData = pd.read_csv('/content/gdrive/MyDrive/TA | ML (HDS)/Deep learning/bank-data.csv', sep = ';')\n",
    "bankData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ks9DOnMn434_"
   },
   "source": [
    "### Part 2: Preprocess data\n",
    "\n",
    "Preprocess the dataset as you have done before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vhvUULRm435A"
   },
   "source": [
    "#### 2.1 Binary encoding\n",
    "\n",
    "Use LabelEncoder to encode the following columns:\n",
    "- y\n",
    "- default\n",
    "- housing\n",
    "- loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kji7ZjdN435A"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "#example\n",
    "bankData['y'] = le.fit_transform(bankData['y'])\n",
    "bankData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t2mufWRC0kwt"
   },
   "outputs": [],
   "source": [
    "#Encode the remaining columns\n",
    "bankData['housing'] = le.fit_transform(bankData['housing'])\n",
    "bankData['default'] = le.fit_transform(bankData['default'])\n",
    "bankData['loan'] = le.fit_transform(bankData['loan'])\n",
    "bankData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YfDPxSIF435B"
   },
   "source": [
    "#### 2.2 Convert categorical variables into dummy columns\n",
    "\n",
    "(1) Use pd.get_dummies to convert the following categorical variales into dummy columns\n",
    "- job\n",
    "- maritial\n",
    "- education\n",
    "- contact\n",
    "- month\n",
    "- poutcome\n",
    "\n",
    "(2) Drop columns that have been converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r34bsIn1435C",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#example\n",
    "bankData = pd.concat([bankData,pd.get_dummies(bankData['job'],prefix='job')],axis=1)\n",
    "bankData = bankData.drop(columns=['job'])\n",
    "bankData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K8tlkopU435D"
   },
   "outputs": [],
   "source": [
    "bankData = pd.concat([bankData,pd.get_dummies(bankData['marital'],prefix='marital')],axis=1)\n",
    "bankData = pd.concat([bankData,pd.get_dummies(bankData['education'],prefix='education')],axis=1)\n",
    "bankData = pd.concat([bankData,pd.get_dummies(bankData['contact'],prefix='contact')],axis=1)\n",
    "bankData = pd.concat([bankData,pd.get_dummies(bankData['month'],prefix='month')],axis=1)\n",
    "bankData = pd.concat([bankData,pd.get_dummies(bankData['poutcome'],prefix='poutcome')],axis=1)\n",
    "\n",
    "bankData = bankData.drop(columns=['marital', 'education', 'contact', 'month', 'poutcome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mmlxgThm435D"
   },
   "outputs": [],
   "source": [
    "bankData.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWcNsOaL435E"
   },
   "source": [
    "#### 2.3 Train/Test separation\n",
    "\n",
    "Perform hold-out method\n",
    "- 60% training set\n",
    "- 40% testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "slrfMUjM435E"
   },
   "outputs": [],
   "source": [
    "bankData_train = bankData.sample(frac = 0.6)\n",
    "bankData_test = bankData.drop(bankData_train.index)\n",
    "print(pd.crosstab(bankData_train['y'],columns = 'count'))\n",
    "print(pd.crosstab(bankData_test['y'],columns = 'count'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XoN9XdV9435F"
   },
   "source": [
    "##### X/y separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SVlkYjio435F"
   },
   "outputs": [],
   "source": [
    "bankData_train_y = bankData_train['y']\n",
    "bankData_train_X = bankData_train.copy()\n",
    "del bankData_train_X['y']\n",
    "\n",
    "bankData_test_y = bankData_test['y']\n",
    "bankData_test_X = bankData_test.copy()\n",
    "del bankData_test_X['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n388IJ35435F"
   },
   "source": [
    "#### 2.4 Feature Scaling\n",
    "\n",
    "It is always a good practice to scale the features so that all of them can be uniformly evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-jZabhza435G"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "standard_scaler = preprocessing.StandardScaler()\n",
    "train_X_scaled_s = pd.DataFrame(standard_scaler.fit_transform(bankData_train_X), columns=bankData_train_X.columns)\n",
    "test_X_scaled_s = pd.DataFrame(standard_scaler.fit_transform(bankData_test_X), columns=bankData_train_X.columns)\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "train_X_scaled_m = pd.DataFrame(min_max_scaler.fit_transform(bankData_train_X),columns=bankData_train_X.columns)\n",
    "test_X_scaled_m = pd.DataFrame(min_max_scaler.fit_transform(bankData_test_X),columns=bankData_train_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JKrKzVIV435H"
   },
   "outputs": [],
   "source": [
    "train_X_scaled_s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NhzkklN6435H"
   },
   "outputs": [],
   "source": [
    "train_X_scaled_m.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9o6Fx1Uo435H"
   },
   "source": [
    "## Artificial Neural Network : sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ixxCzVyl435I"
   },
   "source": [
    "### Part 3: Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iH2Xy43j435I"
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier  \n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=1000)  \n",
    "mlp.fit(train_X_scaled_s, bankData_train_y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZoBOY0T435I"
   },
   "source": [
    "### Part 4: Model Evaluation\n",
    "\n",
    "Evaluation metrics\n",
    "- confusion metrix\n",
    "- accuracy\n",
    "- precision, recall, f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IsPD4M_x435J"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_REPD7xX435J"
   },
   "source": [
    "### Part 5: Model tuning\n",
    "\n",
    "#### Note:\n",
    "\n",
    "After building the classifier, try answering the following questions.\n",
    "\n",
    "1. What is the Accuracy Score?\n",
    "2. If you change your preprosessing method, can you improve the model?\n",
    "3. If you change your parameters setting, can you improve the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kRSpwv7M435J"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A78eyrD9435K"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X_MPCMWZ435K"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1uJ0J3RY435K"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a2rFXoaZ435L"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E5_htGlH435L"
   },
   "source": [
    "## Artificial Neural Network : keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "okmaEg1w435L"
   },
   "source": [
    "Fitting a logistic regression model\n",
    "\n",
    "### Part 3: Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lGgfgTwA435L"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_45344/2067893928.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \"\"\"\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yHy4lmdH435M"
   },
   "outputs": [],
   "source": [
    "train_X_scaled_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DLhWHlWq435M"
   },
   "outputs": [],
   "source": [
    "nn = models.Sequential()\n",
    "nn.add(layers.Dense(48,activation = 'linear',input_shape=(None,48)))\n",
    "nn.add(layers.Dense(1,activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "odaxloDm435N"
   },
   "outputs": [],
   "source": [
    "nn.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JIpe8C_3435N"
   },
   "outputs": [],
   "source": [
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s1T5upu4435O"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_train_add = np.expand_dims(train_X_scaled_s, axis=0)\n",
    "y_train_add = np.expand_dims(bankData_train_y, axis=0)\n",
    "y_train_add = np.expand_dims(y_train_add, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZqEmIUVT435O"
   },
   "outputs": [],
   "source": [
    "y_train_add.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FMpFwPwG435P"
   },
   "outputs": [],
   "source": [
    "history = nn.fit(X_train_add,y_train_add,epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HwufSm3Q435P"
   },
   "source": [
    "### Part 4: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jt3OHQGr435P"
   },
   "outputs": [],
   "source": [
    "X_test_add = np.expand_dims(test_X_scaled_s, axis=0)\n",
    "y_test_add = np.expand_dims(bankData_test_y, axis=0)\n",
    "y_test_add = np.expand_dims(y_test_add, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ij0fx68X435P"
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = nn.evaluate(X_test_add, y_test_add)\n",
    "print('Test Loss: %s\\nTest Accuracy: %s' % (test_loss,test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BeGwm9TY435Q"
   },
   "source": [
    "### Part 5: Model tuning\n",
    "\n",
    "#### Note:\n",
    "\n",
    "After building the classifier, try answering the following questions.\n",
    "\n",
    "1. What is the Accuracy Score?\n",
    "2. If you change your preprosessing method, can you improve the model?\n",
    "3. If you change your parameters setting, can you improve the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1XNg6xPt435Q"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rtveLHNA435R"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FNZysGcs435R"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wy7qcIT8435R"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hYejBerH435R"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "(Lab) Simple Neuron Network.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
